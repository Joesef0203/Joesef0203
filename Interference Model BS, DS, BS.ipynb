{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44caaab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(tracks, frame_number, image_width, image_height):\n",
    "    # Create a directory to save the text files if it doesn't exist\n",
    "    save_dir = 'P-3-4'# Save Label Location\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save the predictions to a text file in YOLOv5 format\n",
    "    save_path = f'{save_dir}/frame_{frame_number}.txt'\n",
    "    with open(save_path, 'w') as f:\n",
    "        for track in tracks:\n",
    "            track_id = track.track_id\n",
    "            ltrb = track.to_ltrb()\n",
    "            bbox = ltrb\n",
    "            class_id = 0    \n",
    "            # Convert normalized coordinates to absolute pixel values\n",
    "            x = (bbox[0] + bbox[2]) / (2 * image_width)\n",
    "            y = (bbox[1] + bbox[3]) / (2 * image_height)\n",
    "            width = (bbox[2] - bbox[0]) / image_width\n",
    "            height = (bbox[3] - bbox[1]) / image_height\n",
    "            if (bbox[3] - bbox[1]) <100 and (bbox[3] - bbox[1])<100 and 0.66<r<1.47:\n",
    "                line = f\"{class_id} {x} {y} {width} {height}\\n\"\n",
    "            f.write(line)\n",
    "def draw_notification(frame):\n",
    "    height, width, _ = frame.shape\n",
    "    square_size = min(height, width) // 10\n",
    "    cv2.rectangle(frame, (width - square_size, 0), (width, square_size), (0, 0, 255), -1)\n",
    "    return frame\n",
    "def adjust_contrast(image, alpha, beta):\n",
    "    \"\"\"\n",
    "    Adjust the contrast of the image using the formula: new_image = alpha * image + beta\n",
    "    \"\"\"\n",
    "    adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return adjusted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680b1938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\admin/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2023-8-19 Python-3.7.16 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46108278 parameters, 0 gradients, 107.6 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device:  cuda\n",
      "Total False Positives: 778\n",
      "Average FPS: 12.62\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "class YoloDetector():\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        \n",
    "        self.model = self.load_model(model_name)\n",
    "        self.classes = self.model.names\n",
    "        #print(self.classes)\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"Using Device: \", self.device)\n",
    "        \n",
    "\n",
    "    def load_model(self, model_name):\n",
    "   \n",
    "        if model_name:\n",
    "            model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_name, force_reload=True)\n",
    "        else:\n",
    "            model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "        return model\n",
    "\n",
    "    def score_frame(self, frame):\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        downscale_factor = 2\n",
    "        width = int(frame.shape[1] / downscale_factor)\n",
    "        height = int(frame.shape[0] / downscale_factor)\n",
    "        frame = cv2.resize(frame, (width,height))\n",
    "        #frame = frame.to(self.device)\n",
    "        \n",
    "        results = self.model(frame)\n",
    "        \n",
    "        labels, cord = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]\n",
    "        \n",
    "        return labels, cord\n",
    "\n",
    "    def class_to_label(self, x):\n",
    "   \n",
    "        return self.classes[int(x)]\n",
    "\n",
    "\n",
    "    def plot_boxes(self, results, frame, height, width, confidence=0.3):\n",
    "    \n",
    "        labels, cord = results\n",
    "        detections = []\n",
    "\n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = width, height\n",
    "        \n",
    "    \n",
    "    \n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            \n",
    "            if row[4] >= confidence:\n",
    "                x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "                \n",
    "                if self.class_to_label(labels[i]) == 'drone':\n",
    "                \n",
    "                    x_center = x1 + (x2 - x1)\n",
    "                    y_center = y1 + ((y2 - y1) / 2)\n",
    "                    \n",
    "                    tlwh = np.asarray([x1, y1, int(x2-x1), int(y2-y1)], dtype=np.float32)\n",
    "                    confidence = float(row[4].item())\n",
    "                    feature = 'drone'\n",
    "                    \n",
    "                    detections.append(([x1, y1, int(x2-x1), int(y2-y1)], row[4].item(), 'drone'))\n",
    "                \n",
    "        \n",
    "        return frame, detections\n",
    "\n",
    "cap = cv2.VideoCapture('validate05.mp4') #Video Input\n",
    "alpha = 2  # Increase this value to increase contrast\n",
    "beta = 2     # Increase this value to make the image brighter or decrease to make it darker\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "detectorbackup = YoloDetector(model_name='Yolov5_StrongSORT_OSNet/yolov5/runs/train/exp20/weights/best.pt')\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "object_tracker = DeepSort(max_age=100,\n",
    "                n_init=2,\n",
    "                nms_max_overlap=1.0,\n",
    "                max_cosine_distance=0.3,\n",
    "                nn_budget=None,\n",
    "                override_track_class=None,\n",
    "                embedder=\"mobilenet\",\n",
    "                half=True,\n",
    "                bgr=True,\n",
    "                embedder_gpu=True,\n",
    "                embedder_model_name=None,\n",
    "                embedder_wts=None,\n",
    "                polygon=False,\n",
    "                today=None)\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True,varThreshold=200,history=50)\n",
    "frame_number = 0\n",
    "total_false_positives = 0\n",
    "new_width = 1920  # New width in pixels\n",
    "new_height = 1080  # New height in pixels\n",
    "out = cv2.VideoWriter('M-3-5.mp4', fourcc, 30.0, (new_width, new_height))#Video Output\n",
    "meanfps=0\n",
    "while cap.isOpened():\n",
    "\n",
    "    succes, img = cap.read()\n",
    "    if not succes:\n",
    "        break\n",
    "    #img = cv2.flip(img, 0)\n",
    "    img = cv2.resize(img, (new_width, new_height))\n",
    "    img = adjust_contrast(img, alpha, beta)\n",
    "    fgmask =fgbg.apply(img, 0.0005)\n",
    " \n",
    "    start = time.perf_counter()\n",
    "    img2 = cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)\n",
    "    r1=0.66\n",
    "    r2=1.47\n",
    "    \n",
    "    #img, detections = detector.plot_boxes(results, img, height=img.shape[0], width=img.shape[1], confidence=0.4)\n",
    "    image_height, image_width = img.shape[:2]\n",
    "    # find the contours of the foreground regions\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # create an empty image for the convex hull\n",
    "    hull_image = np.zeros_like(img)\n",
    "    \n",
    "    # loop through each contour and add its convex hull to the hull image\n",
    "    for contour in contours:\n",
    "        hull = cv2.convexHull(contour)\n",
    "        cv2.drawContours(hull_image, [hull], 0, (0, 255, 0), thickness=1)\n",
    "    \n",
    "    # create a mask of the foreground objects\n",
    "    mask = np.zeros_like(fgmask)\n",
    "    for contour in contours:\n",
    "        cv2.drawContours(mask, [contour], 0, 255, -1)\n",
    "    \n",
    "    # apply the mask to the original frame\n",
    "    masked_frame = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # add the convex hull image to the masked frame\n",
    "    img2 = cv2.addWeighted(masked_frame, 1, hull_image, 1, 0)\n",
    "    results = detectorbackup.score_frame(img2)\n",
    "        \n",
    "    img2, detections = detectorbackup.plot_boxes(tracks, img2, height=img.shape[0], width=img2.shape[1], confidence=0.40)\n",
    "    tracks = object_tracker.update_tracks(detections, frame=img) # bbs expected to be a list of detections, each in tuples of ( [left,top,w,h], confidence, detection_class )\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "        bbox = ltrb\n",
    "        x1 = int(bbox[0])\n",
    "        y1 = int(bbox[1])\n",
    "        x2 = int(bbox[2])\n",
    "        y2 = int(bbox[3])\n",
    "\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        if w==0 or h==0:\n",
    "                r=0\n",
    "        else:\n",
    "            r=w/h\n",
    "        if w <100 and h<100 and r1<r<r2:\n",
    "            frame_with_notification = draw_notification(img)\n",
    "            cv2.putText(img, \"WARNING!\", (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3)\n",
    "            total_false_positives += 1\n",
    "            save_predictions(results, ltrb, frame_number, image_width, image_height)\n",
    "            cv2.rectangle(img,(int(bbox[0]), int(bbox[1])),(int(bbox[2]), int(bbox[3])),(0,0,255),2)\n",
    "            cv2.putText(img, \"ID1: \" + str(track_id), (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "    end = time.perf_counter()\n",
    "    totalTime = end - start\n",
    "    fps = 1 / totalTime\n",
    "    meanfps=meanfps+fps\n",
    "    frame_number += 1\n",
    "    cv2.putText(img, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "    out.write(img)\n",
    "    cv2.imshow('img',cv2.resize(img,None, fx=.5,fy=.5))\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "# Release and destroy all windows before termination\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f'Total False Positives: {total_false_positives}')\n",
    "meanfps=meanfps/(frame_number-1)\n",
    "print(f\"Average FPS: {meanfps:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb9957d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021716017416033625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanfps=meanfps/(frame_number-1)\n",
    "meanfps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0055fbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     611.33,      669.53,      634.38,      693.11])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3fc404d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50126ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2157"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32ba7685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1577"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7118a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
